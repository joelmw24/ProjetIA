{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "import pickle\n",
    "import json\n",
    "from imblearn.over_sampling import SMOTE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I - Préparation des Données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Données avant transformation:\n",
      "   longitude   latitude  haut_tot  haut_tronc  tronc_diam fk_arb_etat  \\\n",
      "0   3.293264  49.840500       6.0         2.0        37.0    EN PLACE   \n",
      "1   3.273380  49.861409      13.0         1.0       160.0    EN PLACE   \n",
      "2   3.289068  49.844513      12.0         3.0       116.0    REMPLACÉ   \n",
      "3   3.302387  49.861778      16.0         3.0       150.0    EN PLACE   \n",
      "4   3.304047  49.858446       5.0         2.0       170.0    Essouché   \n",
      "\n",
      "   age_estim  \n",
      "0       15.0  \n",
      "1       50.0  \n",
      "2       30.0  \n",
      "3       50.0  \n",
      "4       40.0  \n",
      "\n",
      "Données après transformation:\n",
      "   longitude   latitude  haut_tot  haut_tronc  tronc_diam  fk_arb_etat  \\\n",
      "0   3.293264  49.840500       6.0         2.0        37.0            0   \n",
      "1   3.273380  49.861409      13.0         1.0       160.0            0   \n",
      "2   3.289068  49.844513      12.0         3.0       116.0            0   \n",
      "3   3.302387  49.861778      16.0         3.0       150.0            0   \n",
      "4   3.304047  49.858446       5.0         2.0       170.0            1   \n",
      "\n",
      "   age_estim  \n",
      "0       15.0  \n",
      "1       50.0  \n",
      "2       30.0  \n",
      "3       50.0  \n",
      "4       40.0  \n",
      "longitude      0\n",
      "latitude       0\n",
      "haut_tot       0\n",
      "haut_tronc     0\n",
      "tronc_diam     0\n",
      "age_estim      0\n",
      "fk_arb_etat    0\n",
      "dtype: int64\n",
      "      longitude   latitude  haut_tot  haut_tronc  tronc_diam  age_estim  \\\n",
      "0      3.301635  49.865548  1.001937    1.202070    0.108097   0.046213   \n",
      "1      3.272708  49.847591 -0.610010   -0.474180   -0.350711  -0.730176   \n",
      "2      3.309938  49.854962  0.518353   -1.032930    0.923755   0.305009   \n",
      "3      3.290565  49.859053 -0.448816   -0.474180    0.668862   0.201491   \n",
      "4      3.299023  49.834308  0.518353    0.084570    0.159075   0.305009   \n",
      "...         ...        ...       ...         ...         ...        ...   \n",
      "1107   3.302374  49.862184  0.034768    0.084570   -0.690569  -0.730176   \n",
      "1108   3.269194  49.849572 -1.093594   -1.591681   -1.285320  -0.988972   \n",
      "1109   3.279423  49.855017  0.195963    0.643320   -0.350711  -0.212583   \n",
      "1110   3.306403  49.855163 -0.771205   -0.474180   -1.370285  -1.506565   \n",
      "1111   3.294365  49.840780 -1.093594   -0.474180   -1.302313  -0.988972   \n",
      "\n",
      "      fk_arb_etat  \n",
      "0               0  \n",
      "1               0  \n",
      "2               0  \n",
      "3               0  \n",
      "4               0  \n",
      "...           ...  \n",
      "1107            0  \n",
      "1108            0  \n",
      "1109            0  \n",
      "1110            0  \n",
      "1111            0  \n",
      "\n",
      "[1112 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Extraction des données d’intérêt\n",
    "file_arbre = 'Data_Arbre.csv'\n",
    "arbre = pd.read_csv(file_arbre)\n",
    "\n",
    "# Les colonnes pertinentes\n",
    "colonnes_pertinentes = [\"longitude\", \"latitude\", \"haut_tot\", \"haut_tronc\", \"tronc_diam\", \"fk_arb_etat\", \"age_estim\"]\n",
    "data_arbre = arbre[colonnes_pertinentes].copy()\n",
    "print(\"\\nDonnées avant transformation:\")\n",
    "print(data_arbre.head())\n",
    "\n",
    "# Transformation de 'fk_arb_etat' en variable binaire\n",
    "data_arbre['fk_arb_etat'] = (data_arbre['fk_arb_etat'] == 'Essouché').astype(int)\n",
    "print(\"\\nDonnées après transformation:\")\n",
    "print(data_arbre.head())\n",
    "\n",
    "with open('Encodage', 'wb') as f:\n",
    "    pickle.dump(data_arbre, f)\n",
    "\n",
    "# Séparation des caractéristiques et de la cible\n",
    "x = data_arbre.drop(columns=['fk_arb_etat'])\n",
    "y = data_arbre['fk_arb_etat']\n",
    "\n",
    "# Séparation en ensembles d'entraînement (60%), de validation (25%) et de test (15%)\n",
    "x_train_val, x_test, y_train_val, y_test = train_test_split(x, y, test_size=0.15, random_state=42)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_val, y_train_val, test_size=0.25, random_state=42)\n",
    "\n",
    "# Colonnes des coordonnées\n",
    "coordonnes = ['longitude', 'latitude']\n",
    "\n",
    "# Séparer les colonnes des coordonnées pour ne pas les normaliser\n",
    "x_train_coords = x_train[coordonnes]\n",
    "x_val_coords = x_val[coordonnes]\n",
    "x_test_coords = x_test[coordonnes]\n",
    "x_train_features = x_train.drop(columns=coordonnes)\n",
    "x_val_features = x_val.drop(columns=coordonnes)\n",
    "x_test_features = x_test.drop(columns=coordonnes)\n",
    "\n",
    "# Mise à l'échelle des caractéristiques\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled_fit = scaler.fit_transform(x_train_features)\n",
    "x_val_scaled_fit = scaler.transform(x_val_features)\n",
    "x_test_scaled_fit = scaler.transform(x_test_features)\n",
    "\n",
    "with open('Normalisation', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "# Convertir les résultats en DataFrame\n",
    "x_train_scaled_features = pd.DataFrame(x_train_scaled_fit, columns=x_train_features.columns, index=x_train.index)\n",
    "x_val_scaled_features = pd.DataFrame(x_val_scaled_fit, columns=x_val_features.columns, index=x_val.index)\n",
    "x_test_scaled_features = pd.DataFrame(x_test_scaled_fit, columns=x_test_features.columns, index=x_test.index)\n",
    "x_train_scaled = pd.concat([x_train_coords, x_train_scaled_features], axis=1)\n",
    "x_val_scaled = pd.concat([x_val_coords, x_val_scaled_features], axis=1)\n",
    "x_test_scaled = pd.concat([x_test_coords, x_test_scaled_features], axis=1)\n",
    "\n",
    "# Sauvegarde des données de test au format JSON\n",
    "test_data = pd.concat([x_test_scaled.reset_index(drop=True), y_test.reset_index(drop=True)], axis=1)\n",
    "test_data.to_json('test_data.json', orient='records')\n",
    "\n",
    "# Affichage des données de test et vérification des valeurs manquantes\n",
    "print(test_data.isna().sum())\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II - Apprentissage Supervisé pour la régression classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores de précision pour chaque fold : [0.97712834 0.97458704 0.97649301]\n",
      "Précision moyenne : 0.9760694620923337\n",
      "Matrice de confusion :\n",
      " [[1. 0.]\n",
      " [1. 0.]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1537\n",
      "           1       0.00      0.00      0.00        38\n",
      "\n",
      "    accuracy                           0.98      1575\n",
      "   macro avg       0.49      0.50      0.49      1575\n",
      "weighted avg       0.95      0.98      0.96      1575\n",
      "\n",
      "Scores de précision pour chaque fold : [0.5653446  0.4998374  0.59804878]\n",
      "Précision moyenne : 0.554410260747601\n",
      "Matrice de confusion :\n",
      " [[0.9369287  0.0630713 ]\n",
      " [0.66666667 0.33333333]]\n",
      "\n",
      "Rapport de classification :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96      1094\n",
      "           1       0.08      0.33      0.13        18\n",
      "\n",
      "    accuracy                           0.93      1112\n",
      "   macro avg       0.53      0.64      0.55      1112\n",
      "weighted avg       0.97      0.93      0.95      1112\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "sgd_clf.fit(x_train_scaled, y_train)\n",
    "\n",
    "# Prédiction\n",
    "y_pred = sgd_clf.predict(x_val_scaled)\n",
    "\n",
    "# Calcul de la matrice de confusion sur l'ensemble de validation\n",
    "matrix = confusion_matrix(y_val, y_pred, normalize='true')\n",
    "\n",
    "# Validation croisée pour évaluer la performance du modèle\n",
    "scores = cross_val_score(sgd_clf, x_train_scaled, y_train, cv=3, scoring='accuracy')\n",
    "\n",
    "# Affichage des résultats\n",
    "print(\"Scores de précision pour chaque fold :\", scores)\n",
    "print(\"Précision moyenne :\", scores.mean())\n",
    "print(\"Matrice de confusion :\\n\", matrix)\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "#  SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "x_train_res, y_train_res = sm.fit_resample(x_train_scaled, y_train)\n",
    "\n",
    "# Entraînement du modèle sur les données résamplées\n",
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "sgd_clf.fit(x_train_res, y_train_res)\n",
    "\n",
    "# Prédiction sur l'ensemble de test\n",
    "y_pred = sgd_clf.predict(x_test_scaled)\n",
    "\n",
    "# Validation croisée pour évaluer la performance du modèle sur les données résamplées\n",
    "scores = cross_val_score(sgd_clf, x_train_res, y_train_res, cv=3, scoring='accuracy')\n",
    "\n",
    "# Affichage des résultats\n",
    "print(\"Scores de précision pour chaque fold :\", scores)\n",
    "print(\"Précision moyenne :\", scores.mean())\n",
    "print(\"Matrice de confusion :\\n\", confusion_matrix(y_test, y_pred,normalize='true'))\n",
    "print(\"\\nRapport de classification :\\n\", classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores de précision pour chaque fold (validation) : [0.97458704 0.97331639 0.97141042]\n",
      "Précision moyenne (validation) : 0.9731046166878441\n",
      "Matrice de confusion (validation) :\n",
      " [[0.99739753 0.00260247]\n",
      " [1.         0.        ]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1537\n",
      "           1       0.00      0.00      0.00        38\n",
      "\n",
      "    accuracy                           0.97      1575\n",
      "   macro avg       0.49      0.50      0.49      1575\n",
      "weighted avg       0.95      0.97      0.96      1575\n",
      "\n",
      "Scores de précision pour chaque fold  : [0.90084525 0.92162602 0.92780488]\n",
      "Précision moyenne  : 0.9167587159616719\n",
      "Matrice de confusion (test) :\n",
      " [[0.91499086 0.08500914]\n",
      " [0.61111111 0.38888889]]\n",
      "\n",
      "Rapport de classification (test) :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95      1094\n",
      "           1       0.07      0.39      0.12        18\n",
      "\n",
      "    accuracy                           0.91      1112\n",
      "   macro avg       0.53      0.65      0.53      1112\n",
      "weighted avg       0.97      0.91      0.94      1112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gb_clf = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Entraînement du modèle sur les données d'entraînement\n",
    "gb_clf.fit(x_train_scaled, y_train)\n",
    "\n",
    "# Prédiction sur l'ensemble de validation\n",
    "y_pred_val = gb_clf.predict(x_val_scaled)\n",
    "\n",
    "# Calcul de la matrice de confusion sur l'ensemble de validation\n",
    "matrix_val = confusion_matrix(y_val, y_pred_val, normalize='true')\n",
    "\n",
    "# Validation croisée pour évaluer la performance du modèle\n",
    "scores_val = cross_val_score(gb_clf, x_train_scaled, y_train, cv=3, scoring='accuracy')\n",
    "\n",
    "# Affichage des résultats\n",
    "print(\"Scores de précision pour chaque fold (validation) :\", scores_val)\n",
    "print(\"Précision moyenne (validation) :\", scores_val.mean())\n",
    "print(\"Matrice de confusion (validation) :\\n\", matrix_val)\n",
    "print(classification_report(y_val, y_pred_val))\n",
    "\n",
    "# Résampling avec SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "x_train_res, y_train_res = sm.fit_resample(x_train_scaled, y_train)\n",
    "\n",
    "# Utilisation de GradientBoostingClassifier pour le modèle après résampling\n",
    "gb_clf_res = GradientBoostingClassifier(random_state=42)\n",
    "gb_clf_res.fit(x_train_res, y_train_res)\n",
    "\n",
    "# Prédiction sur l'ensemble de test\n",
    "y_pred_test = gb_clf_res.predict(x_test_scaled)\n",
    "\n",
    "# Validation croisée pour évaluer la performance du modèle sur les données résamplées\n",
    "scores_res = cross_val_score(gb_clf_res, x_train_res, y_train_res, cv=3, scoring='accuracy')\n",
    "\n",
    "# Affichage des résultats\n",
    "print(\"Scores de précision pour chaque fold  :\", scores_res)\n",
    "print(\"Précision moyenne  :\", scores_res.mean())\n",
    "print(\"Matrice de confusion (test) :\\n\", confusion_matrix(y_test, y_pred_test, normalize='true'))\n",
    "print(\"\\nRapport de classification (test) :\\n\", classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores de précision pour chaque fold (SVC) : [0.97712834 0.97712834 0.97649301]\n",
      "Précision moyenne (SVC) : 0.9769165607793308\n",
      "Matrice de confusion (SVC) :\n",
      " [[1094    0]\n",
      " [  18    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1094\n",
      "           1       0.00      0.00      0.00        18\n",
      "\n",
      "    accuracy                           0.98      1112\n",
      "   macro avg       0.49      0.50      0.50      1112\n",
      "weighted avg       0.97      0.98      0.98      1112\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores de précision pour chaque fold (RandomForest) : [0.97839898 0.97776366 0.97649301]\n",
      "Précision moyenne (RandomForest) : 0.9775518847945786\n",
      "Matrice de confusion sur l'ensemble de test (RandomForest):\n",
      " [[1089    5]\n",
      " [  16    2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      1094\n",
      "           1       0.29      0.11      0.16        18\n",
      "\n",
      "    accuracy                           0.98      1112\n",
      "   macro avg       0.64      0.55      0.58      1112\n",
      "weighted avg       0.97      0.98      0.98      1112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Modèle SVC\n",
    "svc_clf = SVC(random_state=42)\n",
    "\n",
    "# Entraînement du modèle sur les données d'entraînement mises à l'échelle\n",
    "svc_clf.fit(x_train_scaled, y_train)\n",
    "\n",
    "# Prédiction sur l'ensemble de test\n",
    "y_pred_svc = svc_clf.predict(x_test_scaled)\n",
    "\n",
    "# Calcul de la matrice de confusion sur l'ensemble de test\n",
    "matrix_svc = confusion_matrix(y_test, y_pred_svc)\n",
    "\n",
    "# Validation croisée pour évaluer la performance du modèle\n",
    "scores_svc = cross_val_score(svc_clf, x_train_scaled, y_train, cv=3, scoring='accuracy')\n",
    "\n",
    "# Affichage des résultats\n",
    "print(\"Scores de précision pour chaque fold (SVC) :\", scores_svc)\n",
    "print(\"Précision moyenne (SVC) :\", scores_svc.mean())\n",
    "print(\"Matrice de confusion (SVC) :\\n\", matrix_svc)\n",
    "print(classification_report(y_test, y_pred_svc))\n",
    "\n",
    "# Modèle RandomForest\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Entraînement du modèle sur les données d'entraînement mises à l'échelle\n",
    "rf_clf.fit(x_train_scaled, y_train)\n",
    "\n",
    "# Prédiction sur l'ensemble de validation\n",
    "y_val_pred_rf = rf_clf.predict(x_val_scaled)\n",
    "\n",
    "# Validation croisée pour évaluer la performance du modèle\n",
    "scores_rf = cross_val_score(rf_clf, x_train_scaled, y_train, cv=3, scoring='accuracy')\n",
    "\n",
    "# Prédiction sur l'ensemble de test\n",
    "y_test_pred_rf = rf_clf.predict(x_test_scaled)\n",
    "\n",
    "# Calcul de la matrice de confusion sur l'ensemble de test\n",
    "test_matrix_rf = confusion_matrix(y_test, y_test_pred_rf)\n",
    "\n",
    "# Affichage des résultats pour l'ensemble de test\n",
    "print(\"Scores de précision pour chaque fold (RandomForest) :\", scores_rf)\n",
    "print(\"Précision moyenne (RandomForest) :\", scores_rf.mean())\n",
    "print(\"Matrice de confusion sur l'ensemble de test (RandomForest):\\n\", test_matrix_rf)\n",
    "print(classification_report(y_test, y_test_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III - GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n",
      "[CV] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=hinge, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=hinge, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=hinge, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=hinge, max_iter=3000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=hinge, max_iter=3000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=hinge, max_iter=3000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=modified_huber, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=modified_huber, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=modified_huber, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=modified_huber, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=modified_huber, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=modified_huber, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=modified_huber, max_iter=3000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=modified_huber, max_iter=3000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=modified_huber, max_iter=3000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=squared_hinge, max_iter=3000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=squared_hinge, max_iter=3000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, loss=squared_hinge, max_iter=3000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END .alpha=0.001, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END .alpha=0.001, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END .alpha=0.001, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END .alpha=0.001, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END .alpha=0.001, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END .alpha=0.001, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END .alpha=0.001, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END .alpha=0.001, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END .alpha=0.001, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END .alpha=0.001, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END .alpha=0.001, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END .alpha=0.001, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END .alpha=0.001, loss=hinge, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END .alpha=0.001, loss=hinge, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END .alpha=0.001, loss=hinge, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END .alpha=0.001, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END .alpha=0.001, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END .alpha=0.001, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, loss=hinge, max_iter=3000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, loss=hinge, max_iter=3000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, loss=hinge, max_iter=3000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, loss=modified_huber, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, loss=modified_huber, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, loss=modified_huber, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, loss=modified_huber, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, loss=modified_huber, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, loss=modified_huber, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, loss=modified_huber, max_iter=3000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, loss=modified_huber, max_iter=3000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, loss=modified_huber, max_iter=3000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.001, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.001, loss=squared_hinge, max_iter=3000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, loss=squared_hinge, max_iter=3000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.001, loss=squared_hinge, max_iter=3000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ..alpha=0.01, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END ..alpha=0.01, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END ..alpha=0.01, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END ..alpha=0.01, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END ..alpha=0.01, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END ..alpha=0.01, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ..alpha=0.01, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END ..alpha=0.01, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END ..alpha=0.01, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END ..alpha=0.01, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END ..alpha=0.01, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END ..alpha=0.01, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END ..alpha=0.01, loss=hinge, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END ..alpha=0.01, loss=hinge, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END ..alpha=0.01, loss=hinge, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END ..alpha=0.01, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END ..alpha=0.01, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END ..alpha=0.01, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, loss=hinge, max_iter=3000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, loss=hinge, max_iter=3000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, loss=hinge, max_iter=3000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, loss=modified_huber, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, loss=modified_huber, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, loss=modified_huber, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, loss=modified_huber, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, loss=modified_huber, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, loss=modified_huber, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, loss=modified_huber, max_iter=3000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, loss=modified_huber, max_iter=3000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, loss=modified_huber, max_iter=3000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.01, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.01, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.01, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.01, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.01, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.01, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END alpha=0.01, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.01, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.01, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.1s\n",
      "[CV] END alpha=0.01, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.01, loss=squared_hinge, max_iter=3000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.01, loss=squared_hinge, max_iter=3000, penalty=elasticnet; total time=   0.1s\n",
      "[CV] END alpha=0.01, loss=squared_hinge, max_iter=3000, penalty=elasticnet; total time=   0.0s\n",
      "Meilleurs paramètres trouvés pour SGD :\n",
      "{'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 1000, 'penalty': 'elasticnet'}\n",
      "Meilleur score de validation croisée pour SGD :\n",
      "0.9771283354510801\n",
      "Rapport de classification sur l'ensemble de test pour SGD :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1094\n",
      "           1       0.00      0.00      0.00        18\n",
      "\n",
      "    accuracy                           0.98      1112\n",
      "   macro avg       0.49      0.50      0.50      1112\n",
      "weighted avg       0.97      0.98      0.98      1112\n",
      "\n",
      "Enregistrement du modèle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Stochastic Gradient Descent\n",
    "param_grid_sgd = {\n",
    "    'loss': ['hinge', 'modified_huber', 'squared_hinge'],\n",
    "    'penalty': ['l2', 'l1', 'elasticnet'],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'max_iter': [1000, 2000, 3000],\n",
    "}\n",
    "\n",
    "grid_search_sgd = GridSearchCV(SGDClassifier(random_state=42), param_grid_sgd, cv=3, scoring='accuracy', verbose=2, error_score='raise')\n",
    "grid_search_sgd.fit(x_train_scaled, y_train)  # entraînement \n",
    "\n",
    "print(\"Meilleurs paramètres trouvés pour SGD :\")\n",
    "print(grid_search_sgd.best_params_)\n",
    "print(\"Meilleur score de validation croisée pour SGD :\")\n",
    "print(grid_search_sgd.best_score_)\n",
    "\n",
    "best_model_sgd = grid_search_sgd.best_estimator_\n",
    "y_pred_sgd = best_model_sgd.predict(x_test_scaled)\n",
    "\n",
    "print(\"Rapport de classification sur l'ensemble de test pour SGD :\")\n",
    "print(classification_report(y_test, y_pred_sgd))\n",
    "\n",
    "# Enregistrement du meilleur modèle\n",
    "with open('best_sgd_model.pkl', 'wb') as file:\n",
    "    pickle.dump(best_model_sgd, file)\n",
    "print(\"Enregistrement du modèle\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Machines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "[CV] END learning_rate=0.1, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END learning_rate=0.1, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END learning_rate=0.1, min_samples_leaf=1, min_samples_split=3, n_estimators=50; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, min_samples_leaf=1, min_samples_split=3, n_estimators=50; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, min_samples_leaf=1, min_samples_split=3, n_estimators=50; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, min_samples_leaf=1, min_samples_split=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, min_samples_leaf=1, min_samples_split=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, min_samples_leaf=1, min_samples_split=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, min_samples_leaf=1, min_samples_split=3, n_estimators=200; total time=   0.5s\n",
      "[CV] END learning_rate=0.1, min_samples_leaf=1, min_samples_split=3, n_estimators=200; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, min_samples_leaf=1, min_samples_split=3, n_estimators=200; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, min_samples_leaf=2, min_samples_split=3, n_estimators=50; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, min_samples_leaf=2, min_samples_split=3, n_estimators=50; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, min_samples_leaf=2, min_samples_split=3, n_estimators=50; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, min_samples_leaf=2, min_samples_split=3, n_estimators=200; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, min_samples_leaf=2, min_samples_split=3, n_estimators=200; total time=   0.5s\n",
      "[CV] END learning_rate=0.1, min_samples_leaf=2, min_samples_split=3, n_estimators=200; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END learning_rate=0.1, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.5s\n",
      "[CV] END learning_rate=0.1, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END learning_rate=0.001, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END learning_rate=0.001, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END learning_rate=0.001, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, min_samples_leaf=1, min_samples_split=3, n_estimators=50; total time=   0.1s\n",
      "[CV] END learning_rate=0.001, min_samples_leaf=1, min_samples_split=3, n_estimators=50; total time=   0.1s\n",
      "[CV] END learning_rate=0.001, min_samples_leaf=1, min_samples_split=3, n_estimators=50; total time=   0.1s\n",
      "[CV] END learning_rate=0.001, min_samples_leaf=1, min_samples_split=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, min_samples_leaf=1, min_samples_split=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, min_samples_leaf=1, min_samples_split=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, min_samples_leaf=1, min_samples_split=3, n_estimators=200; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, min_samples_leaf=1, min_samples_split=3, n_estimators=200; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, min_samples_leaf=1, min_samples_split=3, n_estimators=200; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END learning_rate=0.001, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END learning_rate=0.001, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END learning_rate=0.001, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END learning_rate=0.001, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END learning_rate=0.001, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END learning_rate=0.001, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END learning_rate=0.001, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, min_samples_leaf=2, min_samples_split=3, n_estimators=50; total time=   0.1s\n",
      "[CV] END learning_rate=0.001, min_samples_leaf=2, min_samples_split=3, n_estimators=50; total time=   0.1s\n",
      "[CV] END learning_rate=0.001, min_samples_leaf=2, min_samples_split=3, n_estimators=50; total time=   0.1s\n",
      "[CV] END learning_rate=0.001, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, min_samples_leaf=2, min_samples_split=3, n_estimators=200; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, min_samples_leaf=2, min_samples_split=3, n_estimators=200; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, min_samples_leaf=2, min_samples_split=3, n_estimators=200; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END learning_rate=0.001, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END learning_rate=0.001, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END learning_rate=0.001, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.5s\n",
      "[CV] END learning_rate=0.001, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.5s\n",
      "Meilleurs paramètres trouvés :\n",
      "{'learning_rate': 0.1, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Meilleur score de validation croisée :\n",
      "0.9771283354510801\n",
      "Rapport de classification sur l'ensemble de test :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1094\n",
      "           1       0.20      0.06      0.09        18\n",
      "\n",
      "    accuracy                           0.98      1112\n",
      "   macro avg       0.59      0.53      0.54      1112\n",
      "weighted avg       0.97      0.98      0.98      1112\n",
      "\n",
      "Enregistrement du modèle\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Machines\n",
    "param_grid_gbc = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.1, 0.001],\n",
    "    'min_samples_split': [2, 3, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "grid_search_gbc = GridSearchCV(GradientBoostingClassifier(random_state=42), param_grid_gbc, cv=3, scoring='accuracy', verbose=2)\n",
    "grid_search_gbc.fit(x_train_scaled, y_train)  # entraînement \n",
    "\n",
    "print(\"Meilleurs paramètres trouvés :\")\n",
    "print(grid_search_gbc.best_params_)\n",
    "print(\"Meilleur score de validation croisée :\")\n",
    "print(grid_search_gbc.best_score_)\n",
    "\n",
    "best_model_gbc = grid_search_gbc.best_estimator_\n",
    "y_pred_gbc = best_model_gbc.predict(x_test_scaled)\n",
    "\n",
    "print(\"Rapport de classification sur l'ensemble de test :\")\n",
    "print(classification_report(y_test, y_pred_gbc))\n",
    "\n",
    "# Enregistrement du meilleur modèle\n",
    "with open('best_gbm_model.pkl', 'wb') as file:\n",
    "    pickle.dump(best_model_gbc, file)\n",
    "print(\"Enregistrement du modèle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "[CV] END .......................C=0.1, degree=1, gamma=scale; total time=   0.0s\n",
      "[CV] END .......................C=0.1, degree=1, gamma=scale; total time=   0.0s\n",
      "[CV] END .......................C=0.1, degree=1, gamma=scale; total time=   0.0s\n",
      "[CV] END ........................C=0.1, degree=1, gamma=auto; total time=   0.0s\n",
      "[CV] END ........................C=0.1, degree=1, gamma=auto; total time=   0.0s\n",
      "[CV] END ........................C=0.1, degree=1, gamma=auto; total time=   0.0s\n",
      "[CV] END .......................C=0.1, degree=2, gamma=scale; total time=   0.0s\n",
      "[CV] END .......................C=0.1, degree=2, gamma=scale; total time=   0.0s\n",
      "[CV] END .......................C=0.1, degree=2, gamma=scale; total time=   0.0s\n",
      "[CV] END ........................C=0.1, degree=2, gamma=auto; total time=   0.0s\n",
      "[CV] END ........................C=0.1, degree=2, gamma=auto; total time=   0.0s\n",
      "[CV] END ........................C=0.1, degree=2, gamma=auto; total time=   0.0s\n",
      "[CV] END .......................C=0.1, degree=3, gamma=scale; total time=   0.0s\n",
      "[CV] END .......................C=0.1, degree=3, gamma=scale; total time=   0.0s\n",
      "[CV] END .......................C=0.1, degree=3, gamma=scale; total time=   0.0s\n",
      "[CV] END ........................C=0.1, degree=3, gamma=auto; total time=   0.0s\n",
      "[CV] END ........................C=0.1, degree=3, gamma=auto; total time=   0.0s\n",
      "[CV] END ........................C=0.1, degree=3, gamma=auto; total time=   0.0s\n",
      "[CV] END .........................C=1, degree=1, gamma=scale; total time=   0.0s\n",
      "[CV] END .........................C=1, degree=1, gamma=scale; total time=   0.0s\n",
      "[CV] END .........................C=1, degree=1, gamma=scale; total time=   0.0s\n",
      "[CV] END ..........................C=1, degree=1, gamma=auto; total time=   0.1s\n",
      "[CV] END ..........................C=1, degree=1, gamma=auto; total time=   0.1s\n",
      "[CV] END ..........................C=1, degree=1, gamma=auto; total time=   0.1s\n",
      "[CV] END .........................C=1, degree=2, gamma=scale; total time=   0.0s\n",
      "[CV] END .........................C=1, degree=2, gamma=scale; total time=   0.0s\n",
      "[CV] END .........................C=1, degree=2, gamma=scale; total time=   0.0s\n",
      "[CV] END ..........................C=1, degree=2, gamma=auto; total time=   0.1s\n",
      "[CV] END ..........................C=1, degree=2, gamma=auto; total time=   0.1s\n",
      "[CV] END ..........................C=1, degree=2, gamma=auto; total time=   0.1s\n",
      "[CV] END .........................C=1, degree=3, gamma=scale; total time=   0.0s\n",
      "[CV] END .........................C=1, degree=3, gamma=scale; total time=   0.0s\n",
      "[CV] END .........................C=1, degree=3, gamma=scale; total time=   0.0s\n",
      "[CV] END ..........................C=1, degree=3, gamma=auto; total time=   0.1s\n",
      "[CV] END ..........................C=1, degree=3, gamma=auto; total time=   0.1s\n",
      "[CV] END ..........................C=1, degree=3, gamma=auto; total time=   0.1s\n",
      "[CV] END ........................C=10, degree=1, gamma=scale; total time=   0.0s\n",
      "[CV] END ........................C=10, degree=1, gamma=scale; total time=   0.0s\n",
      "[CV] END ........................C=10, degree=1, gamma=scale; total time=   0.0s\n",
      "[CV] END .........................C=10, degree=1, gamma=auto; total time=   0.1s\n",
      "[CV] END .........................C=10, degree=1, gamma=auto; total time=   0.1s\n",
      "[CV] END .........................C=10, degree=1, gamma=auto; total time=   0.1s\n",
      "[CV] END ........................C=10, degree=2, gamma=scale; total time=   0.0s\n",
      "[CV] END ........................C=10, degree=2, gamma=scale; total time=   0.0s\n",
      "[CV] END ........................C=10, degree=2, gamma=scale; total time=   0.0s\n",
      "[CV] END .........................C=10, degree=2, gamma=auto; total time=   0.1s\n",
      "[CV] END .........................C=10, degree=2, gamma=auto; total time=   0.1s\n",
      "[CV] END .........................C=10, degree=2, gamma=auto; total time=   0.1s\n",
      "[CV] END ........................C=10, degree=3, gamma=scale; total time=   0.0s\n",
      "[CV] END ........................C=10, degree=3, gamma=scale; total time=   0.0s\n",
      "[CV] END ........................C=10, degree=3, gamma=scale; total time=   0.0s\n",
      "[CV] END .........................C=10, degree=3, gamma=auto; total time=   0.1s\n",
      "[CV] END .........................C=10, degree=3, gamma=auto; total time=   0.1s\n",
      "[CV] END .........................C=10, degree=3, gamma=auto; total time=   0.1s\n",
      "[CV] END .......................C=100, degree=1, gamma=scale; total time=   0.1s\n",
      "[CV] END .......................C=100, degree=1, gamma=scale; total time=   0.1s\n",
      "[CV] END .......................C=100, degree=1, gamma=scale; total time=   0.1s\n",
      "[CV] END ........................C=100, degree=1, gamma=auto; total time=   0.2s\n",
      "[CV] END ........................C=100, degree=1, gamma=auto; total time=   0.2s\n",
      "[CV] END ........................C=100, degree=1, gamma=auto; total time=   0.2s\n",
      "[CV] END .......................C=100, degree=2, gamma=scale; total time=   0.1s\n",
      "[CV] END .......................C=100, degree=2, gamma=scale; total time=   0.1s\n",
      "[CV] END .......................C=100, degree=2, gamma=scale; total time=   0.1s\n",
      "[CV] END ........................C=100, degree=2, gamma=auto; total time=   0.2s\n",
      "[CV] END ........................C=100, degree=2, gamma=auto; total time=   0.2s\n",
      "[CV] END ........................C=100, degree=2, gamma=auto; total time=   0.2s\n",
      "[CV] END .......................C=100, degree=3, gamma=scale; total time=   0.1s\n",
      "[CV] END .......................C=100, degree=3, gamma=scale; total time=   0.1s\n",
      "[CV] END .......................C=100, degree=3, gamma=scale; total time=   0.1s\n",
      "[CV] END ........................C=100, degree=3, gamma=auto; total time=   0.2s\n",
      "[CV] END ........................C=100, degree=3, gamma=auto; total time=   0.2s\n",
      "[CV] END ........................C=100, degree=3, gamma=auto; total time=   0.2s\n",
      "Meilleurs paramètres trouvés:\n",
      "{'C': 10, 'degree': 1, 'gamma': 'auto'}\n",
      "Meilleur score de validation croisée :\n",
      "0.9775518847945786\n",
      "Rapport de classification sur l'ensemble de test :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1094\n",
      "           1       0.00      0.00      0.00        18\n",
      "\n",
      "    accuracy                           0.98      1112\n",
      "   macro avg       0.49      0.50      0.49      1112\n",
      "weighted avg       0.97      0.98      0.97      1112\n",
      "\n",
      "Enregistrement du modèle \n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machines\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'degree': [1, 2, 3]\n",
    "}\n",
    "\n",
    "grid_search_svm = GridSearchCV(SVC(random_state=42), param_grid_svm, cv=3, scoring='accuracy', verbose=2)\n",
    "grid_search_svm.fit(x_train_scaled, y_train)  # entraînement \n",
    "\n",
    "print(\"Meilleurs paramètres trouvés:\")\n",
    "print(grid_search_svm.best_params_)\n",
    "print(\"Meilleur score de validation croisée :\")\n",
    "print(grid_search_svm.best_score_)\n",
    "\n",
    "best_model_svm = grid_search_svm.best_estimator_\n",
    "y_pred_svm = best_model_svm.predict(x_test_scaled)\n",
    "\n",
    "print(\"Rapport de classification sur l'ensemble de test :\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "\n",
    "# Enregistrement du meilleur modèle\n",
    "with open('best_svm_model.pkl', 'wb') as file:\n",
    "    pickle.dump(best_model_svm, file)\n",
    "print(\"Enregistrement du modèle \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
